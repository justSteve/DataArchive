"""
Inspection Report Generator

Generates Claude-friendly markdown reports for drive inspection sessions.
Reports are designed to be easily parsed by Claude for analysis and
decision-making during the interactive review process.
"""

import os
import json
from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import datetime

import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.logger import get_logger

logger = get_logger(__name__)


class InspectionReportGenerator:
    """
    Generates Claude-friendly markdown reports for inspection sessions.

    Report format is optimized for:
    - Quick summary scanning
    - Decision point presentation
    - Structured data extraction by Claude
    - Human readability
    """

    def __init__(self, output_dir: str = "output/reports"):
        """
        Initialize the report generator.

        Args:
            output_dir: Directory for saving markdown reports
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"InspectionReportGenerator initialized (output_dir={output_dir})")

    def _format_bytes(self, bytes_val: int) -> str:
        """Format bytes to human-readable string"""
        if bytes_val >= 1024 * 1024 * 1024:
            return f"{bytes_val / (1024 * 1024 * 1024):.1f} GB"
        elif bytes_val >= 1024 * 1024:
            return f"{bytes_val / (1024 * 1024):.1f} MB"
        elif bytes_val >= 1024:
            return f"{bytes_val / 1024:.1f} KB"
        else:
            return f"{bytes_val} bytes"

    def _format_count(self, count: int) -> str:
        """Format count with commas"""
        return f"{count:,}"

    def generate(self, review_report) -> str:
        """
        Generate a markdown report from a ReviewReport.

        Args:
            review_report: ReviewReport object or dict from Pass 4

        Returns:
            Path to the generated markdown file
        """
        # Handle both object and dict inputs
        if hasattr(review_report, 'to_dict'):
            data = review_report.to_dict()
        else:
            data = review_report

        session_id = data.get('session_id', 'unknown')
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"session_{session_id}_{timestamp}.md"
        output_path = self.output_dir / filename

        # Generate report content
        content = self._generate_content(data)

        # Write to file
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)

        logger.info(f"Generated report: {output_path}")
        return str(output_path)

    def _generate_content(self, data: Dict[str, Any]) -> str:
        """Generate the markdown content"""
        lines = []

        # Header
        drive_model = data.get('drive_model', 'Unknown Drive')
        drive_serial = data.get('drive_serial', 'Unknown')
        lines.append(f"# Drive Inspection Report: {drive_model} (S/N: {drive_serial})")
        lines.append("")

        # Metadata
        lines.append(f"**Session ID:** {data.get('session_id', 'N/A')}")
        lines.append(f"**Drive Path:** {data.get('drive_path', 'N/A')}")
        lines.append(f"**Inspection Time:** {data.get('inspection_time', 'N/A')}")
        lines.append("")

        # Summary section
        lines.extend(self._generate_summary_section(data))

        # Previous passes section
        lines.extend(self._generate_pass_results_section(data))

        # Decision points section
        lines.extend(self._generate_decision_points_section(data))

        # Recommendations section
        lines.extend(self._generate_recommendations_section(data))

        # Resolved decisions section (if any)
        if data.get('resolved_decisions'):
            lines.extend(self._generate_resolved_decisions_section(data))

        # Footer
        lines.append("---")
        lines.append("")
        lines.append(f"*Report generated by DataArchive v2 on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")

        return "\n".join(lines)

    def _generate_summary_section(self, data: Dict[str, Any]) -> List[str]:
        """Generate the summary section"""
        lines = []
        lines.append("## Summary")
        lines.append("")

        health = data.get('health_summary', {})
        os_info = data.get('os_summary', {})
        meta = data.get('metadata_summary', {})

        # Quick summary line
        health_status = health.get('status', 'Unknown')
        os_name = os_info.get('os_name', 'Unknown')
        version = os_info.get('version', '')
        if version:
            os_display = f"{os_name} {version}"
        else:
            os_display = os_name

        total_files = meta.get('total_files', 0)
        total_size = meta.get('total_size_bytes', 0)

        lines.append(f"- **Health:** {health_status} (Score: {health.get('score', 'N/A')}/100)")
        lines.append(f"- **OS:** {os_display}")
        lines.append(f"- **Files:** {self._format_count(total_files)} ({self._format_bytes(total_size)})")

        # Duplicates if present
        dup_groups = meta.get('duplicate_groups', 0)
        if dup_groups > 0:
            wasted = meta.get('wasted_bytes', 0)
            lines.append(f"- **Duplicates:** {dup_groups} groups ({self._format_bytes(wasted)} potentially recoverable)")

        lines.append("")
        return lines

    def _generate_pass_results_section(self, data: Dict[str, Any]) -> List[str]:
        """Generate the pass results section"""
        lines = []
        lines.append("## Inspection Results")
        lines.append("")

        # Pass 1: Health
        lines.append("### Pass 1: Drive Health")
        lines.append("")
        health = data.get('health_summary', {})

        if health.get('status') == 'not_available':
            lines.append("*Health inspection not completed*")
        else:
            lines.append(f"- **Overall Status:** {health.get('status', 'Unknown')}")
            lines.append(f"- **Health Score:** {health.get('score', 'N/A')}/100")
            lines.append(f"- **ChkDsk:** {'Passed' if health.get('chkdsk_success') else 'Issues detected or not run'}")
            lines.append(f"- **SMART Data:** {'Available' if health.get('smart_available') else 'Not available'}")

            if health.get('errors'):
                lines.append("")
                lines.append("**Errors:**")
                for error in health.get('errors', [])[:5]:
                    lines.append(f"- {error}")

            if health.get('warnings'):
                lines.append("")
                lines.append("**Warnings:**")
                for warning in health.get('warnings', [])[:5]:
                    lines.append(f"- {warning}")

        lines.append("")

        # Pass 2: OS Detection
        lines.append("### Pass 2: Operating System Detection")
        lines.append("")
        os_info = data.get('os_summary', {})

        if os_info.get('status') == 'not_available':
            lines.append("*OS detection not completed*")
        else:
            os_type = os_info.get('os_type', 'Unknown')
            os_name = os_info.get('os_name', 'Unknown')
            version = os_info.get('version', '')
            build = os_info.get('build_number', '')

            lines.append(f"- **OS Type:** {os_type}")
            lines.append(f"- **OS Name:** {os_name}")
            if version:
                lines.append(f"- **Version:** {version}")
            if build:
                lines.append(f"- **Build:** {build}")
            if os_info.get('edition'):
                lines.append(f"- **Edition:** {os_info.get('edition')}")
            lines.append(f"- **Boot Capable:** {'Yes' if os_info.get('boot_capable') else 'No'}")
            lines.append(f"- **Detection Confidence:** {os_info.get('confidence', 'Unknown')}")
            lines.append(f"- **Detection Method:** {os_info.get('detection_method', 'None')}")

            # User profiles
            profiles = os_info.get('user_profiles', [])
            if profiles:
                lines.append("")
                lines.append(f"**User Profiles ({len(profiles)}):**")
                for profile in profiles[:10]:
                    lines.append(f"- {profile}")
                if len(profiles) > 10:
                    lines.append(f"- *...and {len(profiles) - 10} more*")

            # Windows features
            features = os_info.get('windows_features', {})
            active_features = [k for k, v in features.items() if v]
            if active_features:
                lines.append("")
                lines.append("**Detected Features:**")
                for feature in active_features:
                    lines.append(f"- {feature.replace('has_', '').replace('_', ' ').title()}")

        lines.append("")

        # Pass 3: Metadata
        lines.append("### Pass 3: File Metadata")
        lines.append("")
        meta = data.get('metadata_summary', {})

        if meta.get('status') == 'not_available':
            lines.append("*Metadata capture not completed*")
        else:
            lines.append(f"- **Total Files:** {self._format_count(meta.get('total_files', 0))}")
            lines.append(f"- **Total Folders:** {self._format_count(meta.get('total_folders', 0))}")
            lines.append(f"- **Total Size:** {self._format_bytes(meta.get('total_size_bytes', 0))}")
            lines.append(f"- **Files Hashed:** {self._format_count(meta.get('files_hashed', 0))}")

            # Date range
            oldest = meta.get('oldest_file')
            newest = meta.get('newest_file')
            if oldest and newest:
                lines.append(f"- **Date Range:** {oldest[:10]} to {newest[:10]}")

            # Duplicates
            dup_groups = meta.get('duplicate_groups', 0)
            if dup_groups > 0:
                lines.append("")
                lines.append("**Duplicate Analysis:**")
                lines.append(f"- Duplicate Groups: {dup_groups}")
                lines.append(f"- Total Duplicate Files: {meta.get('total_duplicate_files', 0)}")
                lines.append(f"- Potential Space Savings: {self._format_bytes(meta.get('wasted_bytes', 0))}")
                if meta.get('cross_scan_duplicates', 0) > 0:
                    lines.append(f"- Cross-Drive Duplicates: {meta.get('cross_scan_duplicates', 0)}")

            # Top extensions
            top_exts = meta.get('top_extensions', [])
            if top_exts:
                lines.append("")
                lines.append("**Top File Types:**")
                for ext_info in top_exts[:5]:
                    lines.append(f"- {ext_info.get('extension', 'unknown')}: {self._format_count(ext_info.get('count', 0))} files")

        lines.append("")
        return lines

    def _generate_decision_points_section(self, data: Dict[str, Any]) -> List[str]:
        """Generate the decision points section"""
        lines = []
        decision_points = data.get('decision_points', [])

        if not decision_points:
            lines.append("## Decision Points")
            lines.append("")
            lines.append("*No decisions required for this inspection.*")
            lines.append("")
            return lines

        lines.append("## Decision Points")
        lines.append("")
        lines.append("The following decisions require input before proceeding:")
        lines.append("")

        for i, dp in enumerate(decision_points, 1):
            resolved = dp.get('resolved', False)
            status = "RESOLVED" if resolved else "PENDING"

            lines.append(f"### {i}. {dp.get('title', 'Unknown Decision')} [{status}]")
            lines.append("")
            lines.append(dp.get('description', ''))
            lines.append("")

            if resolved:
                lines.append(f"**Resolution:** `{dp.get('resolution')}`")
                if dp.get('resolution_notes'):
                    lines.append(f"**Notes:** {dp.get('resolution_notes')}")
            else:
                lines.append("**Options:**")
                lines.append("")
                lines.append("| Option | Label | Description |")
                lines.append("|--------|-------|-------------|")

                options = dp.get('options', [])
                default = dp.get('default_option')

                for opt in options:
                    opt_id = opt.get('id', '')
                    label = opt.get('label', '')
                    desc = opt.get('description', '')
                    if opt_id == default:
                        label = f"**{label}** (default)"
                    lines.append(f"| `{opt_id}` | {label} | {desc} |")

            lines.append("")

            # Context info
            context = dp.get('context', {})
            if context:
                lines.append("<details>")
                lines.append("<summary>Additional Context</summary>")
                lines.append("")
                lines.append("```json")
                lines.append(json.dumps(context, indent=2, default=str))
                lines.append("```")
                lines.append("</details>")
                lines.append("")

        return lines

    def _generate_recommendations_section(self, data: Dict[str, Any]) -> List[str]:
        """Generate the recommendations section"""
        lines = []
        recommendations = data.get('recommendations', [])
        warnings = data.get('warnings', [])
        errors = data.get('errors', [])

        lines.append("## Recommended Actions")
        lines.append("")

        if errors:
            lines.append("### Errors")
            lines.append("")
            for error in errors:
                lines.append(f"- {error}")
            lines.append("")

        if warnings:
            lines.append("### Warnings")
            lines.append("")
            for warning in warnings:
                lines.append(f"- {warning}")
            lines.append("")

        if recommendations:
            lines.append("### Recommendations")
            lines.append("")
            for rec in recommendations:
                # Highlight priority items
                if rec.upper().startswith("PRIORITY"):
                    lines.append(f"- **{rec}**")
                else:
                    lines.append(f"- {rec}")
            lines.append("")
        else:
            lines.append("*No specific recommendations at this time.*")
            lines.append("")

        return lines

    def _generate_resolved_decisions_section(self, data: Dict[str, Any]) -> List[str]:
        """Generate section for previously resolved decisions"""
        lines = []
        resolved = data.get('resolved_decisions', [])

        if not resolved:
            return lines

        lines.append("## Previously Recorded Decisions")
        lines.append("")
        lines.append("| Decision Type | Value | Decided By | Timestamp |")
        lines.append("|---------------|-------|------------|-----------|")

        for decision in resolved:
            dtype = decision.get('decision_type', 'Unknown')
            value = decision.get('decision_value', 'Unknown')
            by = decision.get('decided_by', 'user')
            when = decision.get('decided_at', 'Unknown')
            if when and len(when) > 19:
                when = when[:19]
            lines.append(f"| {dtype} | `{value}` | {by} | {when} |")

        lines.append("")
        return lines

    def generate_summary_only(self, review_report) -> str:
        """
        Generate a brief summary suitable for inclusion in other documents.

        Args:
            review_report: ReviewReport object or dict from Pass 4

        Returns:
            Brief markdown summary string
        """
        if hasattr(review_report, 'to_dict'):
            data = review_report.to_dict()
        else:
            data = review_report

        lines = []

        drive_model = data.get('drive_model', 'Unknown')
        drive_serial = data.get('drive_serial', 'Unknown')
        lines.append(f"**{drive_model}** (S/N: {drive_serial})")

        health = data.get('health_summary', {})
        os_info = data.get('os_summary', {})
        meta = data.get('metadata_summary', {})

        parts = []
        parts.append(f"Health: {health.get('status', 'Unknown')}")

        os_name = os_info.get('os_name', 'Unknown')
        if os_name != 'Unknown':
            parts.append(f"OS: {os_name}")

        total_files = meta.get('total_files', 0)
        total_size = meta.get('total_size_bytes', 0)
        if total_files > 0:
            parts.append(f"Files: {self._format_count(total_files)} ({self._format_bytes(total_size)})")

        pending = len([d for d in data.get('decision_points', []) if not d.get('resolved')])
        if pending > 0:
            parts.append(f"Decisions: {pending} pending")

        lines.append(" | ".join(parts))

        return "\n".join(lines)


def generate_inspection_report(review_report, output_dir: str = "output/reports") -> str:
    """
    Convenience function to generate an inspection report.

    Args:
        review_report: ReviewReport object or dict
        output_dir: Directory for saving reports

    Returns:
        Path to the generated report
    """
    generator = InspectionReportGenerator(output_dir)
    return generator.generate(review_report)


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='Generate Inspection Report')
    parser.add_argument('json_file', help='Path to JSON file containing review report')
    parser.add_argument('--output-dir', default='output/reports', help='Output directory')

    args = parser.parse_args()

    # Load JSON
    with open(args.json_file, 'r') as f:
        data = json.load(f)

    # Generate report
    generator = InspectionReportGenerator(args.output_dir)
    output_path = generator.generate(data)

    print(f"Report generated: {output_path}")
